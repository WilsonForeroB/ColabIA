{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGl3WWCE+rZhcWoYmDnf5V"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **LLMs Locales en la Nube: Ollama + RAG con LangChain**\n",
        "\n",
        "**Objetivo de la clase:**\n",
        "Aprender a levantar un servidor de LLMs en Google Colab (GPU gratuita),\n",
        "exponerlo al exterior con ngrok, y construir un sistema RAG (Retrieval-Augmented\n",
        "Generation) con LangChain que responda preguntas sobre documentos propios.\n",
        "\n",
        "## ¬øQu√© es RAG y por qu√© importa?\n",
        "\n",
        "Un LLM \"de base\" solo conoce lo que vio durante su entrenamiento.\n",
        "RAG resuelve esto en 3 pasos:\n",
        "\n",
        "  1. üìÑ **Indexar** tus documentos (convertirlos en vectores)\n",
        "  2. üîç **Recuperar** los fragmentos m√°s relevantes para cada pregunta\n",
        "  3. üí¨ **Generar** una respuesta usando esos fragmentos como contexto\n",
        "\n",
        "```\n",
        "Pregunta ‚îÄ‚îÄ‚ñ∫ Recuperador ‚îÄ‚îÄ‚ñ∫ Fragmentos relevantes ‚îÄ‚îÄ‚ñ∫ LLM ‚îÄ‚îÄ‚ñ∫ Respuesta\n",
        "                  ‚ñ≤\n",
        "            Base vectorial\n",
        "            (tus documentos)\n",
        "```\n",
        "\n",
        "## Requisitos previos\n",
        "- Cuenta Google con acceso a Colab\n",
        "- Cuenta ngrok gratuita: https://dashboard.ngrok.com/signup\n",
        "- Auth Token de ngrok: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "‚ö†Ô∏è Antes de empezar: **Runtime ‚Üí Change runtime type ‚Üí T4 GPU**"
      ],
      "metadata": {
        "id": "SN-aKKgm26lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================================================\n",
        "# üßπ LIMPIEZA (ejecutar al terminar la sesi√≥n)\n",
        "# ===========================================================================\n",
        "\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "subprocess.run(['pkill', '-f', 'ollama'], capture_output=True)\n",
        "print(\"‚úÖ T√∫nel y servidor cerrados.\")"
      ],
      "metadata": {
        "id": "IGqfpgJJD7-6",
        "outputId": "e7db2726-1c97-4251-db2d-fe192d12c483",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ T√∫nel y servidor cerrados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VO0PVctz2bb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13e4dced-99a4-4ee7-fbf0-7318924bdb81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GPU disponible:\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n"
          ]
        }
      ],
      "source": [
        "# ===========================================================================\n",
        "# PASO 0: Verificar GPU\n",
        "# ===========================================================================\n",
        "# Siempre verificamos primero que tenemos GPU disponible.\n",
        "# Sin GPU, los modelos tardan 10-20x m√°s ‚Üí clase inviable.\n",
        "\n",
        "import subprocess\n",
        "\n",
        "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "if result.returncode != 0:\n",
        "    raise RuntimeError(\n",
        "        \"‚ùå No se detect√≥ GPU.\\n\"\n",
        "        \"Ve a Runtime ‚Üí Change runtime type ‚Üí T4 GPU y vuelve a ejecutar.\"\n",
        "    )\n",
        "\n",
        "print(\"‚úÖ GPU disponible:\")\n",
        "print(result.stdout.split('\\n')[8])  # L√≠nea con el modelo de GPU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ===========================================================================\n",
        "# PASO 1: Instalar Ollama\n",
        "# ===========================================================================\n",
        "# Ollama es un servidor que gestiona modelos LLM localmente.\n",
        "# Expone una API REST en el puerto 11434, compatible con la API de OpenAI.\n",
        "#\n",
        "# Dependencias del sistema:\n",
        "#   - zstd: para descomprimir el binario de Ollama\n",
        "#   - pciutils: para que Ollama detecte la GPU (¬°sin esto corre en CPU!)\n",
        "\n",
        "import os\n",
        "os.environ['DEBIAN_FRONTEND'] = 'noninteractive'\n",
        "\n",
        "print(\"üì¶ Instalando dependencias del sistema...\")\n",
        "!sudo apt-get update -qq 2>/dev/null\n",
        "!sudo apt-get install -y -qq zstd pciutils 2>/dev/null\n",
        "\n",
        "print(\"\\nüì• Instalando Ollama...\")\n",
        "!curl -fsSL https://ollama.com/install.sh | sh 2>&1 | grep -v 'systemd'\n",
        "\n",
        "!ollama --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80CVXI0z30OR",
        "outputId": "bafdf693-396b-4dfb-c72c-2ad43ffb904f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Instalando dependencias del sistema...\n",
            "Selecting previously unselected package pci.ids.\n",
            "(Reading database ... 121852 files and directories currently installed.)\n",
            "Preparing to unpack .../pci.ids_0.0~2022.01.22-1ubuntu0.1_all.deb ...\n",
            "Unpacking pci.ids (0.0~2022.01.22-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpci3:amd64.\n",
            "Preparing to unpack .../libpci3_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking libpci3:amd64 (1:3.7.0-6) ...\n",
            "Selecting previously unselected package pciutils.\n",
            "Preparing to unpack .../pciutils_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking pciutils (1:3.7.0-6) ...\n",
            "Selecting previously unselected package zstd.\n",
            "Preparing to unpack .../zstd_1.4.8+dfsg-3build1_amd64.deb ...\n",
            "Unpacking zstd (1.4.8+dfsg-3build1) ...\n",
            "Setting up pci.ids (0.0~2022.01.22-1ubuntu0.1) ...\n",
            "Setting up libpci3:amd64 (1:3.7.0-6) ...\n",
            "Setting up zstd (1.4.8+dfsg-3build1) ...\n",
            "Setting up pciutils (1:3.7.0-6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "\n",
            "üì• Instalando Ollama...\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading ollama-linux-amd64.tar.zst\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "Warning: could not connect to a running Ollama instance\n",
            "Warning: client version is 0.16.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================================\n",
        "# PASO 2: Instalar librer√≠as Python\n",
        "# ===========================================================================\n",
        "# - pyngrok: cliente Python para el t√∫nel ngrok\n",
        "# - ollama: cliente oficial para la API de Ollama\n",
        "# - langchain + langchain-ollama: framework de orquestaci√≥n de LLMs\n",
        "# - langchain-community: integraciones de terceros (vectorstores, loaders, etc.)\n",
        "# - faiss-cpu: librer√≠a de b√∫squeda vectorial eficiente (de Meta)\n",
        "#   Usamos la versi√≥n CPU porque FAISS corre en RAM, no en VRAM\n",
        "\n",
        "print(\"üì¶ Instalando librer√≠as Python...\")\n",
        "!pip install -qq pyngrok ollama\n",
        "!pip install -qq langchain langchain-ollama langchain-community langchain-text-splitters\n",
        "!pip install -qq faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4lP8hTY4HJj",
        "outputId": "a0706171-59da-488f-8675-e7455d149d59"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Instalando librer√≠as Python...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================================\n",
        "# PASO 3: Configurar ngrok\n",
        "# ===========================================================================\n",
        "# ngrok crea un t√∫nel HTTPS entre internet y un puerto local de Colab.\n",
        "# Necesitamos esto porque Colab no tiene IP p√∫blica directa.\n",
        "#\n",
        "# Configura tu token en Colab Secrets (icono üîë en el panel izquierdo):\n",
        "#   Nombre: NGROK_AUTHTOKEN\n",
        "#   Valor: tu token de https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    NGROK_AUTHTOKEN = userdata.get('NGROK_AUTHTOKEN')\n",
        "    print(f\"‚úÖ Token cargado: {NGROK_AUTHTOKEN[:2]}...{NGROK_AUTHTOKEN[-2:]}\")\n",
        "except Exception:\n",
        "    raise ValueError(\n",
        "        \"‚ùå Token de ngrok no encontrado.\\n\"\n",
        "        \"A√±√°delo en Colab Secrets (üîë) con el nombre NGROK_AUTHTOKEN.\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5GAwBf54J7l",
        "outputId": "c7677e3b-1ab7-47a4-bccb-89a056b2afef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Token cargado: 39...8e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================================\n",
        "# PASO 4: Iniciar el servidor Ollama\n",
        "# ===========================================================================\n",
        "# Lanzamos Ollama como proceso en background.\n",
        "# OLLAMA_HOST=0.0.0.0 es necesario para que ngrok pueda alcanzarlo.\n",
        "\n",
        "import subprocess, time, requests\n",
        "\n",
        "os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "\n",
        "print(\"üöÄ Iniciando servidor Ollama...\")\n",
        "ollama_proc = subprocess.Popen(\n",
        "    ['ollama', 'serve'],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.PIPE\n",
        ")\n",
        "time.sleep(5)\n",
        "\n",
        "# Verificar que el servidor responde\n",
        "for intento in range(3):\n",
        "    try:\n",
        "        r = requests.get('http://localhost:11434', timeout=10)\n",
        "        print(f\"‚úÖ Servidor activo: {r.text.strip()}\")\n",
        "        break\n",
        "    except requests.ConnectionError:\n",
        "        print(f\"   Intento {intento + 1}/3... esperando\")\n",
        "        time.sleep(5)\n",
        "else:\n",
        "    raise RuntimeError(\"‚ùå El servidor Ollama no arranc√≥ correctamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enR0M9JW4WxA",
        "outputId": "0e2800ac-6b96-4c9c-cd35-6562241d749c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Iniciando servidor Ollama...\n",
            "‚úÖ Servidor activo: Ollama is running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#===========================================================================\n",
        "# PASO 5: Crear el t√∫nel ngrok\n",
        "# ===========================================================================\n",
        "# host_header=\"localhost:11434\" es CR√çTICO.\n",
        "# Ollama solo acepta peticiones cuyo header \"Host\" sea localhost.\n",
        "# Sin este par√°metro, todas las peticiones v√≠a ngrok ser√≠an rechazadas.\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()           # Cerrar t√∫neles previos si los hubiera\n",
        "time.sleep(2)\n",
        "ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "\n",
        "tunnel = ngrok.connect(\n",
        "    addr='11434',\n",
        "    proto='http',\n",
        "    host_header='localhost:11434'\n",
        ")\n",
        "OLLAMA_URL = tunnel.public_url\n",
        "\n",
        "print(f\"\\nüåê Servidor expuesto en: {OLLAMA_URL}\")\n",
        "print(f\"   Prueba en el navegador: {OLLAMA_URL}/api/tags\")"
      ],
      "metadata": {
        "id": "w7cr6HWo7qmy",
        "outputId": "89a8139a-cf35-4690-bf9a-97801cfd53e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üåê Servidor expuesto en: https://mckinley-sly-wretchedly.ngrok-free.dev\n",
            "   Prueba en el navegador: https://mckinley-sly-wretchedly.ngrok-free.dev/api/tags\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================================================\n",
        "# PASO 6: Descargar el modelo\n",
        "# ===========================================================================\n",
        "# Usamos qwen3:4b: ligero (~2.5 GB), r√°pido en T4, y muy capaz en espa√±ol.\n",
        "# Alternativas si quieres m√°s calidad (a costa de velocidad):\n",
        "#   - qwen3:8b  (~5 GB, excelente calidad)\n",
        "#   - llama3.1:8b (~5 GB, referencia open-source)\n",
        "#   - mistral:7b (~4 GB, muy eficiente)\n",
        "\n",
        "MODEL = 'qwen3:4b'\n",
        "\n",
        "print(f\"üì• Descargando {MODEL} (puede tardar 2-5 minutos)...\")\n",
        "!ollama pull {MODEL}\n",
        "\n",
        "print(f\"\\n‚úÖ Modelos disponibles:\")\n",
        "!ollama list"
      ],
      "metadata": {
        "id": "iwVgQEKK7-r3",
        "outputId": "8d470d89-8633-411f-a4df-93043ad5c213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Descargando qwen3:4b (puede tardar 2-5 minutos)...\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\n",
            "‚úÖ Modelos disponibles:\n",
            "NAME        ID              SIZE      MODIFIED               \n",
            "qwen3:4b    359d7dd4bcda    2.5 GB    Less than a second ago    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================================================\n",
        "# PASO 7: Verificar que el modelo usa GPU\n",
        "# ===========================================================================\n",
        "# Enviamos una petici√≥n corta para cargar el modelo en VRAM.\n",
        "# Luego confirmamos con `ollama ps` que aparece \"GPU\" y no \"CPU\".\n",
        "# Si falla aumentar el tiempo de espera (timeout)\n",
        "\n",
        "import requests, json\n",
        "\n",
        "print(\"üî• Cargando modelo en GPU...\")\n",
        "r = requests.post(\n",
        "    'http://localhost:11434/api/generate',\n",
        "    json={\"model\": MODEL, \"prompt\": \"Hola\", \"stream\": False},\n",
        "    timeout=120\n",
        ")\n",
        "print(\"   Modelo cargado.\")\n",
        "\n",
        "print(\"\\nüìä Estado del modelo (debe decir GPU):\")\n",
        "!ollama ps\n",
        "\n",
        "print(\"\\nüñ•Ô∏è  Uso de VRAM:\")\n",
        "!nvidia-smi --query-gpu=name,memory.used,memory.total --format=csv,noheader"
      ],
      "metadata": {
        "id": "UmLTawhm9Bj4",
        "outputId": "da937d03-abdc-43fb-cd0b-1c32b0362fa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî• Cargando modelo en GPU...\n",
            "   Modelo cargado.\n",
            "\n",
            "üìä Estado del modelo (debe decir GPU):\n",
            "NAME        ID              SIZE      PROCESSOR    CONTEXT    UNTIL              \n",
            "qwen3:4b    359d7dd4bcda    3.6 GB    100% GPU     4096       4 minutes from now    \n",
            "\n",
            "üñ•Ô∏è  Uso de VRAM:\n",
            "Tesla T4, 3223 MiB, 15360 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================================================\n",
        "# PASO 8: Probar el LLM directamente (SIN RAG)\n",
        "# ===========================================================================\n",
        "# Antes de construir el RAG, veamos la limitaci√≥n que queremos resolver:\n",
        "# el modelo no conoce informaci√≥n privada o reciente.\n",
        "#\n",
        "# Preguntaremos sobre una empresa ficticia ‚Üí el modelo inventar√° o dir√°\n",
        "# que no sabe. Esto motiva la necesidad del RAG.\n",
        "\n",
        "import ollama as ollama_client\n",
        "\n",
        "client = ollama_client.Client(host=OLLAMA_URL)\n",
        "\n",
        "PREGUNTA_DEMO = \"¬øCu√°les son los productos que ofrece TechNova Solutions y cu√°l es su precio?\"\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ü§ñ LLM SIN contexto (respuesta de base)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Pregunta: {PREGUNTA_DEMO}\\n\")\n",
        "\n",
        "respuesta = client.generate(model=MODEL, prompt=PREGUNTA_DEMO)\n",
        "print(\"Respuesta:\")\n",
        "print(respuesta['response'])\n",
        "print(\"\\nüí° Observaci√≥n: el modelo no conoce TechNova Solutions.\")\n",
        "print(\"   Responder√° que no tiene informaci√≥n o inventar√° datos.\")\n",
        "print(\"   Esto es lo que RAG viene a resolver.\")"
      ],
      "metadata": {
        "id": "9EQALnvF9WmN",
        "outputId": "d0222051-2495-404a-8ef7-5241a9eb8a9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ü§ñ LLM SIN contexto (respuesta de base)\n",
            "============================================================\n",
            "Pregunta: ¬øCu√°les son los productos que ofrece TechNova Solutions y cu√°l es su precio?\n",
            "\n",
            "Respuesta:\n",
            "No tengo informaci√≥n espec√≠fica sobre los productos y precios de TechNova Solutions en mi base de conocimientos. Es posible que esta empresa sea ficticia, tenga un nombre similar a otra compa√±√≠a, o que los detalles no est√©n disponibles en los datos que he recibido. \n",
            "\n",
            "Para obtener informaci√≥n precisa, te recomiendo:\n",
            "1. Visitar su **sitio web oficial**.\n",
            "2. Contactar directamente a TechNova Solutions a trav√©s de su correo o tel√©fono.\n",
            "3. Revisar plataformas de comercio electr√≥nico o cat√°logos p√∫blicos si aplica.\n",
            "\n",
            "Los precios suelen variar seg√∫n el paquete, regi√≥n, condiciones de uso y otros factores, por lo que siempre es importante confirmar con la fuente oficial. ¬°Espero que te sea √∫til! üòä\n",
            "\n",
            "üí° Observaci√≥n: el modelo no conoce TechNova Solutions.\n",
            "   Responder√° que no tiene informaci√≥n o inventar√° datos.\n",
            "   Esto es lo que RAG viene a resolver.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================================================\n",
        "# PASO 9: Preparar los documentos (base de conocimiento)\n",
        "# ===========================================================================\n",
        "# En un caso real, estos documentos ser√≠an PDFs, p√°ginas web, bases de datos, etc.\n",
        "# Aqu√≠ usamos texto plano para mantener el ejemplo claro y reproducible.\n",
        "#\n",
        "# Concepto clave: los documentos se dividen en \"chunks\" (fragmentos).\n",
        "# Cada chunk se convierte en un vector (embedding) para poder buscar\n",
        "# por similitud sem√°ntica, no por palabras exactas.\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Base de conocimiento: documentaci√≥n interna de una empresa ficticia\n",
        "documentos_raw = [\n",
        "    Document(\n",
        "        page_content=\"\"\"\n",
        "        TechNova Solutions - Cat√°logo de Productos 2024\n",
        "\n",
        "        1. DataSync Pro\n",
        "           Plataforma de sincronizaci√≥n de datos en tiempo real.\n",
        "           Precio: 299‚Ç¨/mes por empresa (hasta 10 usuarios).\n",
        "           Incluye: dashboard anal√≠tico, API REST, soporte 24/7.\n",
        "\n",
        "        2. CloudGuard Enterprise\n",
        "           Suite de seguridad cloud con detecci√≥n de amenazas por IA.\n",
        "           Precio: 599‚Ç¨/mes. Incluye auditor√≠as semanales automatizadas.\n",
        "\n",
        "        3. InsightBoard\n",
        "           Herramienta de Business Intelligence con visualizaciones interactivas.\n",
        "           Precio: 149‚Ç¨/mes (plan b√°sico) o 349‚Ç¨/mes (plan avanzado con predicciones).\n",
        "        \"\"\",\n",
        "        metadata={\"fuente\": \"catalogo_productos.pdf\", \"seccion\": \"precios\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"\n",
        "        TechNova Solutions - Pol√≠tica de Soporte T√©cnico\n",
        "\n",
        "        Niveles de soporte disponibles:\n",
        "        - Nivel B√°sico (incluido en todos los planes): tickets por email,\n",
        "          tiempo de respuesta m√°ximo 48 horas laborables.\n",
        "        - Nivel Premium (50‚Ç¨/mes adicionales): chat en vivo y tel√©fono,\n",
        "          tiempo de respuesta m√°ximo 4 horas, gestor de cuenta dedicado.\n",
        "        - Nivel Enterprise (incluido en CloudGuard): soporte 24/7,\n",
        "          tiempo de respuesta m√°ximo 1 hora, ingeniero de soporte asignado.\n",
        "\n",
        "        Para escalar un ticket a nivel cr√≠tico, enviar email a:\n",
        "        soporte-critico@technova.es con asunto [CR√çTICO].\n",
        "        \"\"\",\n",
        "        metadata={\"fuente\": \"politica_soporte.pdf\", \"seccion\": \"soporte\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"\"\"\n",
        "        TechNova Solutions - Preguntas Frecuentes (FAQ)\n",
        "\n",
        "        P: ¬øPuedo probar los productos antes de comprar?\n",
        "        R: S√≠. Todos los productos ofrecen per√≠odo de prueba gratuito de 14 d√≠as,\n",
        "           sin tarjeta de cr√©dito requerida. Accede desde technova.es/trial.\n",
        "\n",
        "        P: ¬øHay descuentos para startups o ONGs?\n",
        "        R: S√≠. Ofrecemos 40% de descuento para startups de menos de 2 a√±os\n",
        "           y 50% para ONGs registradas. Contactar a ventas@technova.es.\n",
        "\n",
        "        P: ¬øLos datos se almacenan en Europa?\n",
        "        R: S√≠. Todos los datos se almacenan en centros de datos certificados\n",
        "           ISO 27001 ubicados en Frankfurt y Madrid, cumpliendo con el RGPD.\n",
        "\n",
        "        P: ¬øSe puede integrar con herramientas existentes como Slack o Jira?\n",
        "        R: DataSync Pro e InsightBoard tienen integraciones nativas con Slack,\n",
        "           Jira, Notion y m√°s de 50 herramientas via Zapier.\n",
        "        \"\"\",\n",
        "        metadata={\"fuente\": \"faq.pdf\", \"seccion\": \"preguntas_frecuentes\"}\n",
        "    ),\n",
        "]\n",
        "\n",
        "print(f\"üìÑ {len(documentos_raw)} documentos cargados.\")\n",
        "print(f\"   Fuentes: {[d.metadata['fuente'] for d in documentos_raw]}\")"
      ],
      "metadata": {
        "id": "caQ-zZ6Q-PAA",
        "outputId": "662f571c-c3d6-4c10-d2d0-786fef655971",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ 3 documentos cargados.\n",
            "   Fuentes: ['catalogo_productos.pdf', 'politica_soporte.pdf', 'faq.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================================================\n",
        "# PASO 10: Dividir documentos en chunks\n",
        "# ===========================================================================\n",
        "# ¬øPor qu√© dividir? Los LLMs tienen l√≠mite de contexto (tokens que pueden\n",
        "# \"leer\" a la vez). Adem√°s, recuperar chunks peque√±os y precisos es m√°s\n",
        "# efectivo que enviar documentos enteros.\n",
        "#\n",
        "# chunk_size: tama√±o m√°ximo de cada fragmento (en caracteres)\n",
        "# chunk_overlap: solapamiento entre chunks para no perder contexto en los bordes\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,       # Cada chunk: hasta 500 caracteres\n",
        "    chunk_overlap=50,     # Los √∫ltimos 50 chars de un chunk se repiten al inicio del siguiente\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \"]  # Prioridad de separaci√≥n: p√°rrafos > l√≠neas > frases\n",
        ")\n",
        "\n",
        "chunks = splitter.split_documents(documentos_raw)\n",
        "\n",
        "print(f\"‚úÇÔ∏è  Documentos divididos en {len(chunks)} chunks.\")\n",
        "print(f\"\\n   Ejemplo ‚Äî Chunk #1:\")\n",
        "print(f\"   Fuente: {chunks[0].metadata['fuente']}\")\n",
        "print(f\"   Texto: {chunks[0].page_content[:200]}...\")"
      ],
      "metadata": {
        "id": "wbNDBfYO_ebm",
        "outputId": "61afbe16-9422-4546-9642-e76b3e3ff45f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÇÔ∏è  Documentos divididos en 7 chunks.\n",
            "\n",
            "   Ejemplo ‚Äî Chunk #1:\n",
            "   Fuente: catalogo_productos.pdf\n",
            "   Texto: TechNova Solutions - Cat√°logo de Productos 2024\n",
            "\n",
            "        1. DataSync Pro\n",
            "           Plataforma de sincronizaci√≥n de datos en tiempo real.\n",
            "           Precio: 299‚Ç¨/mes por empresa (hasta 10 usuarios).\n",
            " ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================================================\n",
        "# PASO 11: Crear embeddings y la base vectorial\n",
        "# ===========================================================================\n",
        "# Los embeddings son representaciones num√©ricas del significado de un texto.\n",
        "# Textos sem√°nticamente similares tienen vectores cercanos en el espacio.\n",
        "#\n",
        "# Usamos OllamaEmbeddings con nomic-embed-text: modelo ligero (~274 MB)\n",
        "# dise√±ado espec√≠ficamente para embeddings, mucho m√°s eficiente que usar\n",
        "# un modelo de chat para esto.\n",
        "#\n",
        "# FAISS (Facebook AI Similarity Search) almacena los vectores en memoria\n",
        "# y permite b√∫squedas de similitud muy r√°pidas (algoritmo HNSW).\n",
        "\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Descargar el modelo de embeddings\n",
        "print(\"üì• Descargando modelo de embeddings (nomic-embed-text, ~274 MB)...\")\n",
        "!ollama pull nomic-embed-text\n",
        "\n",
        "# Crear el objeto de embeddings\n",
        "embeddings = OllamaEmbeddings(\n",
        "    base_url=OLLAMA_URL,\n",
        "    model=\"nomic-embed-text\"\n",
        ")\n",
        "\n",
        "# Crear la base vectorial indexando todos los chunks\n",
        "# Este proceso: texto ‚Üí embedding (vector) ‚Üí almacenado en FAISS\n",
        "print(\"\\nüî¢ Generando embeddings e indexando chunks...\")\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "print(f\"‚úÖ Base vectorial creada con {vectorstore.index.ntotal} vectores.\")\n",
        "print(f\"   Dimensi√≥n de cada vector: {vectorstore.index.d}\")"
      ],
      "metadata": {
        "id": "hSYcX936ByLA",
        "outputId": "dcced992-caeb-434c-ce36-1db7e57e6ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Descargando modelo de embeddings (nomic-embed-text, ~274 MB)...\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n",
            "\n",
            "üî¢ Generando embeddings e indexando chunks...\n",
            "‚úÖ Base vectorial creada con 7 vectores.\n",
            "   Dimensi√≥n de cada vector: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================================================\n",
        "# PASO 12: Probar el recuperador (Retriever)\n",
        "# ===========================================================================\n",
        "# El retriever es el componente que, dada una pregunta, busca los chunks\n",
        "# m√°s relevantes en la base vectorial por similitud sem√°ntica.\n",
        "#\n",
        "# Esto funciona porque la pregunta tambi√©n se convierte en un vector,\n",
        "# y se buscan los vectores de chunks m√°s cercanos (distancia coseno).\n",
        "\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",   # B√∫squeda por similitud coseno\n",
        "    search_kwargs={\"k\": 2}      # Recuperar los 2 chunks m√°s relevantes\n",
        ")\n",
        "\n",
        "# Probemos manualmente el retriever\n",
        "pregunta_test = \"¬øCu√°nto cuesta el plan de soporte premium?\"\n",
        "\n",
        "docs_recuperados = retriever.invoke(pregunta_test)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üîç TEST DEL RECUPERADOR\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Pregunta: {pregunta_test}\")\n",
        "print(f\"\\nChunks recuperados ({len(docs_recuperados)}):\")\n",
        "for i, doc in enumerate(docs_recuperados, 1):\n",
        "    print(f\"\\n  [{i}] Fuente: {doc.metadata['fuente']}\")\n",
        "    print(f\"       Texto: {doc.page_content[:300]}...\")\n",
        "\n",
        "print(\"\\nüí° El retriever encontr√≥ el chunk relevante sin buscar por palabras exactas.\")\n",
        "print(\"   Prob√≥ similitud sem√°ntica: 'soporte premium' ‚âà 'Nivel Premium'.\")"
      ],
      "metadata": {
        "id": "E-2lZDEqB9Tm",
        "outputId": "72068772-04c1-4537-d495-aec915ba01e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "üîç TEST DEL RECUPERADOR\n",
            "============================================================\n",
            "Pregunta: ¬øCu√°nto cuesta el plan de soporte premium?\n",
            "\n",
            "Chunks recuperados (2):\n",
            "\n",
            "  [1] Fuente: politica_soporte.pdf\n",
            "       Texto: Niveles de soporte disponibles:\n",
            "        - Nivel B√°sico (incluido en todos los planes): tickets por email,\n",
            "          tiempo de respuesta m√°ximo 48 horas laborables.\n",
            "        - Nivel Premium (50‚Ç¨/mes adicionales): chat en vivo y tel√©fono,\n",
            "          tiempo de respuesta m√°ximo 4 horas, gestor de cuenta d...\n",
            "\n",
            "  [2] Fuente: catalogo_productos.pdf\n",
            "       Texto: 3. InsightBoard\n",
            "           Herramienta de Business Intelligence con visualizaciones interactivas.\n",
            "           Precio: 149‚Ç¨/mes (plan b√°sico) o 349‚Ç¨/mes (plan avanzado con predicciones)....\n",
            "\n",
            "üí° El retriever encontr√≥ el chunk relevante sin buscar por palabras exactas.\n",
            "   Prob√≥ similitud sem√°ntica: 'soporte premium' ‚âà 'Nivel Premium'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================================================\n",
        "# PASO 13: Construir la cadena RAG con LangChain\n",
        "# ===========================================================================\n",
        "# Aqu√≠ ensamblamos el pipeline completo. LangChain usa el paradigma LCEL\n",
        "# (LangChain Expression Language) con el operador | para encadenar pasos.\n",
        "#\n",
        "# Pipeline:\n",
        "#   {\"context\": retriever, \"question\": passthrough}\n",
        "#        ‚Üì\n",
        "#   prompt_template  (inserta context + question en el prompt)\n",
        "#        ‚Üì\n",
        "#   llm              (genera la respuesta)\n",
        "#        ‚Üì\n",
        "#   StrOutputParser  (extrae el texto de la respuesta)\n",
        "\n",
        "\n",
        "from langchain_ollama import ChatOllama\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# 1. Conectar el LLM de Ollama\n",
        "llm = ChatOllama(\n",
        "    base_url=OLLAMA_URL,\n",
        "    model=MODEL,\n",
        "    temperature=0.1,    # Temperatura baja: respuestas m√°s precisas y consistentes\n",
        "    num_predict=512,    # M√°ximo de tokens a generar\n",
        ")\n",
        "\n",
        "# 2. Definir el prompt\n",
        "# El prompt le indica al LLM c√≥mo debe usar el contexto recuperado.\n",
        "# {context} y {question} son variables que se rellenan en cada llamada.\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Eres un asistente de atenci√≥n al cliente de TechNova Solutions.\n",
        "Responde la pregunta del usuario bas√°ndote √öNICAMENTE en el contexto proporcionado.\n",
        "Si la informaci√≥n no est√° en el contexto, di exactamente: \"No tengo esa informaci√≥n disponible.\"\n",
        "No inventes datos ni precios.\n",
        "\n",
        "Contexto:\n",
        "{context}\n",
        "\n",
        "Pregunta: {question}\n",
        "\n",
        "Respuesta:\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "\n",
        "# 3. Funci√≥n auxiliar para formatear los chunks recuperados\n",
        "def formatear_docs(docs):\n",
        "    \"\"\"Concatena el contenido de los chunks recuperados en un solo string.\"\"\"\n",
        "    return \"\\n\\n---\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# 4. Ensamblar la cadena RAG con LCEL\n",
        "cadena_rag = (\n",
        "    {\n",
        "        \"context\": retriever | formatear_docs,   # Recuperar + formatear\n",
        "        \"question\": RunnablePassthrough()         # Pasar la pregunta tal cual\n",
        "    }\n",
        "    | prompt           # Construir el prompt con context + question\n",
        "    | llm              # Llamar al LLM\n",
        "    | StrOutputParser() # Extraer solo el texto de la respuesta\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Cadena RAG construida:\")\n",
        "print(\"   Pregunta ‚Üí Retriever ‚Üí Chunks ‚Üí Prompt ‚Üí LLM ‚Üí Respuesta\")"
      ],
      "metadata": {
        "id": "rHZlvQqZCNu1",
        "outputId": "55f26ecc-42c6-4824-ac12-ac575f34dce2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Cadena RAG construida:\n",
            "   Pregunta ‚Üí Retriever ‚Üí Chunks ‚Üí Prompt ‚Üí LLM ‚Üí Respuesta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================================================\n",
        "# PASO 14: Probar el sistema RAG\n",
        "# ===========================================================================\n",
        "# Ahora comparamos la misma pregunta del Paso 8 con y sin RAG.\n",
        "# La diferencia debe ser notable: con RAG el modelo responde con datos reales.\n",
        "\n",
        "def preguntar_con_rag(pregunta: str) -> str:\n",
        "    \"\"\"Env√≠a una pregunta al sistema RAG y muestra el resultado.\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"‚ùì Pregunta: {pregunta}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Mostrar qu√© chunks se est√°n recuperando (transparencia del proceso)\n",
        "    docs = retriever.invoke(pregunta)\n",
        "    print(f\"\\nüîç Chunks recuperados ({len(docs)}):\")\n",
        "    for i, doc in enumerate(docs, 1):\n",
        "        print(f\"   [{i}] {doc.metadata['fuente']} ‚Äî {doc.page_content[:100].strip()}...\")\n",
        "\n",
        "    # Generar la respuesta\n",
        "    print(\"\\nüí¨ Respuesta del LLM con contexto:\\n\")\n",
        "    respuesta = cadena_rag.invoke(pregunta)\n",
        "    print(respuesta)\n",
        "    print()\n",
        "    return respuesta\n",
        "\n",
        "\n",
        "# Bater√≠a de preguntas de prueba\n",
        "preguntas = [\n",
        "    \"¬øCu√°les son los productos que ofrece TechNova Solutions y cu√°l es su precio?\",\n",
        "    \"¬øOfrecen descuentos para ONGs?\",\n",
        "    \"¬øC√≥mo puedo escalar un ticket urgente al soporte?\",\n",
        "    \"¬øCu√°l es la capital de Francia?\",   # Pregunta fuera del contexto ‚Üí debe decir que no sabe\n",
        "]\n",
        "\n",
        "for pregunta in preguntas:\n",
        "    preguntar_con_rag(pregunta)\n",
        "    print()"
      ],
      "metadata": {
        "id": "l-oJxDb8DHpd",
        "outputId": "aa8993a2-077e-461a-cc53-6334f05d9133",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "‚ùì Pregunta: ¬øCu√°les son los productos que ofrece TechNova Solutions y cu√°l es su precio?\n",
            "============================================================\n",
            "\n",
            "üîç Chunks recuperados (2):\n",
            "   [1] faq.pdf ‚Äî TechNova Solutions - Preguntas Frecuentes (FAQ)\n",
            "\n",
            "        P: ¬øPuedo probar los productos antes de com...\n",
            "   [2] politica_soporte.pdf ‚Äî Niveles de soporte disponibles:\n",
            "        - Nivel B√°sico (incluido en todos los planes): tickets por e...\n",
            "\n",
            "üí¨ Respuesta del LLM con contexto:\n",
            "\n",
            "No tengo esa informaci√≥n disponible.\n",
            "\n",
            "\n",
            "============================================================\n",
            "‚ùì Pregunta: ¬øOfrecen descuentos para ONGs?\n",
            "============================================================\n",
            "\n",
            "üîç Chunks recuperados (2):\n",
            "   [1] faq.pdf ‚Äî TechNova Solutions - Preguntas Frecuentes (FAQ)\n",
            "\n",
            "        P: ¬øPuedo probar los productos antes de com...\n",
            "   [2] politica_soporte.pdf ‚Äî Niveles de soporte disponibles:\n",
            "        - Nivel B√°sico (incluido en todos los planes): tickets por e...\n",
            "\n",
            "üí¨ Respuesta del LLM con contexto:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "============================================================\n",
            "‚ùì Pregunta: ¬øC√≥mo puedo escalar un ticket urgente al soporte?\n",
            "============================================================\n",
            "\n",
            "üîç Chunks recuperados (2):\n",
            "   [1] politica_soporte.pdf ‚Äî Para escalar un ticket a nivel cr√≠tico, enviar email a:\n",
            "        soporte-critico@technova.es con asun...\n",
            "   [2] politica_soporte.pdf ‚Äî Niveles de soporte disponibles:\n",
            "        - Nivel B√°sico (incluido en todos los planes): tickets por e...\n",
            "\n",
            "üí¨ Respuesta del LLM con contexto:\n",
            "\n",
            "Para escalar un ticket urgente al soporte cr√≠tico, env√≠a un correo electr√≥nico a **soporte-critico@technova.es** con el asunto **[CR√çTICO]**.\n",
            "\n",
            "\n",
            "============================================================\n",
            "‚ùì Pregunta: ¬øCu√°l es la capital de Francia?\n",
            "============================================================\n",
            "\n",
            "üîç Chunks recuperados (2):\n",
            "   [1] politica_soporte.pdf ‚Äî TechNova Solutions - Pol√≠tica de Soporte T√©cnico...\n",
            "   [2] politica_soporte.pdf ‚Äî Niveles de soporte disponibles:\n",
            "        - Nivel B√°sico (incluido en todos los planes): tickets por e...\n",
            "\n",
            "üí¨ Respuesta del LLM con contexto:\n",
            "\n",
            "No tengo esa informaci√≥n disponible.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===========================================================================\n",
        "# üéØ RESUMEN DE LO APRENDIDO\n",
        "# ===========================================================================\n",
        "\"\"\"\n",
        "En esta clase construiste un sistema RAG completo:\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ                    ARQUITECTURA RAG                         ‚îÇ\n",
        "‚îÇ                                                             ‚îÇ\n",
        "‚îÇ  TUS DOCS ‚Üí Chunks ‚Üí Embeddings ‚Üí FAISS (base vectorial)   ‚îÇ\n",
        "‚îÇ                                        ‚Üë                   ‚îÇ\n",
        "‚îÇ  Pregunta ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Retriever           ‚îÇ\n",
        "‚îÇ      ‚îÇ                                     ‚îÇ               ‚îÇ\n",
        "‚îÇ      ‚îÇ              Chunks relevantes ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ\n",
        "‚îÇ      ‚îÇ                    ‚îÇ                                 ‚îÇ\n",
        "‚îÇ      ‚îî‚îÄ‚îÄ‚ñ∫ Prompt ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                 ‚îÇ\n",
        "‚îÇ               ‚îÇ                                             ‚îÇ\n",
        "‚îÇ              LLM (Ollama / qwen3:4b en T4)                  ‚îÇ\n",
        "‚îÇ               ‚îÇ                                             ‚îÇ\n",
        "‚îÇ          Respuesta fundamentada en tus documentos           ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "Componentes LangChain usados:\n",
        "  ‚Ä¢ RecursiveCharacterTextSplitter  ‚Üí dividir documentos en chunks (langchain-text-splitters)\n",
        "  ‚Ä¢ OllamaEmbeddings               ‚Üí convertir texto en vectores\n",
        "  ‚Ä¢ FAISS                          ‚Üí base vectorial para b√∫squeda\n",
        "  ‚Ä¢ ChatOllama                     ‚Üí interfaz con el LLM\n",
        "  ‚Ä¢ ChatPromptTemplate             ‚Üí plantilla de prompt estructurada\n",
        "  ‚Ä¢ LCEL ( | )                     ‚Üí encadenar componentes\n",
        "\n",
        "Pr√≥ximos pasos para explorar:\n",
        "  ‚Ä¢ Usar PDFs reales (PyPDFLoader, WebBaseLoader)\n",
        "  ‚Ä¢ Persistir FAISS en Google Drive para reutilizar entre sesiones\n",
        "  ‚Ä¢ A√±adir memoria conversacional (historial de chat)\n",
        "  ‚Ä¢ Usar Chroma o Qdrant como alternativas a FAISS para producci√≥n\n",
        "  ‚Ä¢ Evaluar la calidad del RAG (RAGAS framework)\n",
        "\"\"\"\n",
        "\n",
        "print(\"üéì ¬°Clase completada!\")\n",
        "print(\"   Tienes un sistema RAG funcional con LLM local, embeddings y b√∫squeda vectorial.\")"
      ],
      "metadata": {
        "id": "zP-ZtjqWD07R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}